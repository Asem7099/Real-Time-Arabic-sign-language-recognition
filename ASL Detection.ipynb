{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.299407</td>\n",
       "      <td>0.679288</td>\n",
       "      <td>0.210996</td>\n",
       "      <td>0.613102</td>\n",
       "      <td>0.150618</td>\n",
       "      <td>0.522777</td>\n",
       "      <td>0.127314</td>\n",
       "      <td>0.438344</td>\n",
       "      <td>0.130090</td>\n",
       "      <td>0.381808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574705</td>\n",
       "      <td>0.358198</td>\n",
       "      <td>0.506751</td>\n",
       "      <td>0.360233</td>\n",
       "      <td>0.452296</td>\n",
       "      <td>0.350743</td>\n",
       "      <td>0.506043</td>\n",
       "      <td>0.339431</td>\n",
       "      <td>0.557486</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.284236</td>\n",
       "      <td>0.729573</td>\n",
       "      <td>0.173007</td>\n",
       "      <td>0.635995</td>\n",
       "      <td>0.111589</td>\n",
       "      <td>0.496627</td>\n",
       "      <td>0.109330</td>\n",
       "      <td>0.372887</td>\n",
       "      <td>0.124706</td>\n",
       "      <td>0.266505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608846</td>\n",
       "      <td>0.450521</td>\n",
       "      <td>0.479627</td>\n",
       "      <td>0.401771</td>\n",
       "      <td>0.453182</td>\n",
       "      <td>0.359019</td>\n",
       "      <td>0.534598</td>\n",
       "      <td>0.349776</td>\n",
       "      <td>0.602132</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.272220</td>\n",
       "      <td>0.750940</td>\n",
       "      <td>0.151656</td>\n",
       "      <td>0.647857</td>\n",
       "      <td>0.090840</td>\n",
       "      <td>0.491623</td>\n",
       "      <td>0.096680</td>\n",
       "      <td>0.370796</td>\n",
       "      <td>0.111904</td>\n",
       "      <td>0.266032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.641275</td>\n",
       "      <td>0.449075</td>\n",
       "      <td>0.491492</td>\n",
       "      <td>0.394166</td>\n",
       "      <td>0.473755</td>\n",
       "      <td>0.353244</td>\n",
       "      <td>0.558699</td>\n",
       "      <td>0.346559</td>\n",
       "      <td>0.625984</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77994</th>\n",
       "      <td>0.526264</td>\n",
       "      <td>0.677356</td>\n",
       "      <td>0.405371</td>\n",
       "      <td>0.684395</td>\n",
       "      <td>0.335519</td>\n",
       "      <td>0.593608</td>\n",
       "      <td>0.387241</td>\n",
       "      <td>0.459165</td>\n",
       "      <td>0.450325</td>\n",
       "      <td>0.363955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523216</td>\n",
       "      <td>0.504606</td>\n",
       "      <td>0.434744</td>\n",
       "      <td>0.525846</td>\n",
       "      <td>0.400675</td>\n",
       "      <td>0.525645</td>\n",
       "      <td>0.488662</td>\n",
       "      <td>0.509252</td>\n",
       "      <td>0.529258</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77995</th>\n",
       "      <td>0.524471</td>\n",
       "      <td>0.684394</td>\n",
       "      <td>0.401440</td>\n",
       "      <td>0.688333</td>\n",
       "      <td>0.329967</td>\n",
       "      <td>0.594382</td>\n",
       "      <td>0.379672</td>\n",
       "      <td>0.458701</td>\n",
       "      <td>0.442549</td>\n",
       "      <td>0.363953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521610</td>\n",
       "      <td>0.506394</td>\n",
       "      <td>0.435055</td>\n",
       "      <td>0.525869</td>\n",
       "      <td>0.390700</td>\n",
       "      <td>0.524858</td>\n",
       "      <td>0.478981</td>\n",
       "      <td>0.509965</td>\n",
       "      <td>0.520434</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77996</th>\n",
       "      <td>0.522581</td>\n",
       "      <td>0.677694</td>\n",
       "      <td>0.397469</td>\n",
       "      <td>0.681666</td>\n",
       "      <td>0.327541</td>\n",
       "      <td>0.590112</td>\n",
       "      <td>0.389733</td>\n",
       "      <td>0.455139</td>\n",
       "      <td>0.467794</td>\n",
       "      <td>0.375672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504175</td>\n",
       "      <td>0.501952</td>\n",
       "      <td>0.435226</td>\n",
       "      <td>0.517287</td>\n",
       "      <td>0.387353</td>\n",
       "      <td>0.518052</td>\n",
       "      <td>0.469302</td>\n",
       "      <td>0.505998</td>\n",
       "      <td>0.502548</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77997</th>\n",
       "      <td>0.532845</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.400254</td>\n",
       "      <td>0.683759</td>\n",
       "      <td>0.322961</td>\n",
       "      <td>0.584981</td>\n",
       "      <td>0.387589</td>\n",
       "      <td>0.448374</td>\n",
       "      <td>0.470393</td>\n",
       "      <td>0.373412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500650</td>\n",
       "      <td>0.511076</td>\n",
       "      <td>0.435591</td>\n",
       "      <td>0.523066</td>\n",
       "      <td>0.379406</td>\n",
       "      <td>0.523126</td>\n",
       "      <td>0.453426</td>\n",
       "      <td>0.514232</td>\n",
       "      <td>0.487108</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77998</th>\n",
       "      <td>0.540281</td>\n",
       "      <td>0.675530</td>\n",
       "      <td>0.413560</td>\n",
       "      <td>0.681854</td>\n",
       "      <td>0.333672</td>\n",
       "      <td>0.586581</td>\n",
       "      <td>0.385783</td>\n",
       "      <td>0.445418</td>\n",
       "      <td>0.457761</td>\n",
       "      <td>0.350155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501399</td>\n",
       "      <td>0.510576</td>\n",
       "      <td>0.428731</td>\n",
       "      <td>0.529173</td>\n",
       "      <td>0.381493</td>\n",
       "      <td>0.530944</td>\n",
       "      <td>0.466449</td>\n",
       "      <td>0.521323</td>\n",
       "      <td>0.500644</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77999 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2      0.299407  0.679288  0.210996  0.613102  0.150618  0.522777  0.127314   \n",
       "3      0.284236  0.729573  0.173007  0.635995  0.111589  0.496627  0.109330   \n",
       "4      0.272220  0.750940  0.151656  0.647857  0.090840  0.491623  0.096680   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "77994  0.526264  0.677356  0.405371  0.684395  0.335519  0.593608  0.387241   \n",
       "77995  0.524471  0.684394  0.401440  0.688333  0.329967  0.594382  0.379672   \n",
       "77996  0.522581  0.677694  0.397469  0.681666  0.327541  0.590112  0.389733   \n",
       "77997  0.532845  0.682315  0.400254  0.683759  0.322961  0.584981  0.387589   \n",
       "77998  0.540281  0.675530  0.413560  0.681854  0.333672  0.586581  0.385783   \n",
       "\n",
       "             7         8         9   ...        33        34        35  \\\n",
       "0      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "2      0.438344  0.130090  0.381808  ...  0.574705  0.358198  0.506751   \n",
       "3      0.372887  0.124706  0.266505  ...  0.608846  0.450521  0.479627   \n",
       "4      0.370796  0.111904  0.266032  ...  0.641275  0.449075  0.491492   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "77994  0.459165  0.450325  0.363955  ...  0.523216  0.504606  0.434744   \n",
       "77995  0.458701  0.442549  0.363953  ...  0.521610  0.506394  0.435055   \n",
       "77996  0.455139  0.467794  0.375672  ...  0.504175  0.501952  0.435226   \n",
       "77997  0.448374  0.470393  0.373412  ...  0.500650  0.511076  0.435591   \n",
       "77998  0.445418  0.457761  0.350155  ...  0.501399  0.510576  0.428731   \n",
       "\n",
       "             36        37        38        39        40        41  42  \n",
       "0      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   A  \n",
       "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   A  \n",
       "2      0.360233  0.452296  0.350743  0.506043  0.339431  0.557486   A  \n",
       "3      0.401771  0.453182  0.359019  0.534598  0.349776  0.602132   A  \n",
       "4      0.394166  0.473755  0.353244  0.558699  0.346559  0.625984   A  \n",
       "...         ...       ...       ...       ...       ...       ...  ..  \n",
       "77994  0.525846  0.400675  0.525645  0.488662  0.509252  0.529258   Z  \n",
       "77995  0.525869  0.390700  0.524858  0.478981  0.509965  0.520434   Z  \n",
       "77996  0.517287  0.387353  0.518052  0.469302  0.505998  0.502548   Z  \n",
       "77997  0.523066  0.379406  0.523126  0.453426  0.514232  0.487108   Z  \n",
       "77998  0.529173  0.381493  0.530944  0.466449  0.521323  0.500644   Z  \n",
       "\n",
       "[77999 rows x 43 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('american.csv')\n",
    "dataset.columns = [i for i in range(dataset.shape[1])]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.299407</td>\n",
       "      <td>0.679288</td>\n",
       "      <td>0.210996</td>\n",
       "      <td>0.613102</td>\n",
       "      <td>0.150618</td>\n",
       "      <td>0.522777</td>\n",
       "      <td>0.127314</td>\n",
       "      <td>0.438344</td>\n",
       "      <td>0.130090</td>\n",
       "      <td>0.381808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574705</td>\n",
       "      <td>0.358198</td>\n",
       "      <td>0.506751</td>\n",
       "      <td>0.360233</td>\n",
       "      <td>0.452296</td>\n",
       "      <td>0.350743</td>\n",
       "      <td>0.506043</td>\n",
       "      <td>0.339431</td>\n",
       "      <td>0.557486</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.284236</td>\n",
       "      <td>0.729573</td>\n",
       "      <td>0.173007</td>\n",
       "      <td>0.635995</td>\n",
       "      <td>0.111589</td>\n",
       "      <td>0.496627</td>\n",
       "      <td>0.109330</td>\n",
       "      <td>0.372887</td>\n",
       "      <td>0.124706</td>\n",
       "      <td>0.266505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608846</td>\n",
       "      <td>0.450521</td>\n",
       "      <td>0.479627</td>\n",
       "      <td>0.401771</td>\n",
       "      <td>0.453182</td>\n",
       "      <td>0.359019</td>\n",
       "      <td>0.534598</td>\n",
       "      <td>0.349776</td>\n",
       "      <td>0.602132</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.272220</td>\n",
       "      <td>0.750940</td>\n",
       "      <td>0.151656</td>\n",
       "      <td>0.647857</td>\n",
       "      <td>0.090840</td>\n",
       "      <td>0.491623</td>\n",
       "      <td>0.096680</td>\n",
       "      <td>0.370796</td>\n",
       "      <td>0.111904</td>\n",
       "      <td>0.266032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.641275</td>\n",
       "      <td>0.449075</td>\n",
       "      <td>0.491492</td>\n",
       "      <td>0.394166</td>\n",
       "      <td>0.473755</td>\n",
       "      <td>0.353244</td>\n",
       "      <td>0.558699</td>\n",
       "      <td>0.346559</td>\n",
       "      <td>0.625984</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77994</th>\n",
       "      <td>0.526264</td>\n",
       "      <td>0.677356</td>\n",
       "      <td>0.405371</td>\n",
       "      <td>0.684395</td>\n",
       "      <td>0.335519</td>\n",
       "      <td>0.593608</td>\n",
       "      <td>0.387241</td>\n",
       "      <td>0.459165</td>\n",
       "      <td>0.450325</td>\n",
       "      <td>0.363955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523216</td>\n",
       "      <td>0.504606</td>\n",
       "      <td>0.434744</td>\n",
       "      <td>0.525846</td>\n",
       "      <td>0.400675</td>\n",
       "      <td>0.525645</td>\n",
       "      <td>0.488662</td>\n",
       "      <td>0.509252</td>\n",
       "      <td>0.529258</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77995</th>\n",
       "      <td>0.524471</td>\n",
       "      <td>0.684394</td>\n",
       "      <td>0.401440</td>\n",
       "      <td>0.688333</td>\n",
       "      <td>0.329967</td>\n",
       "      <td>0.594382</td>\n",
       "      <td>0.379672</td>\n",
       "      <td>0.458701</td>\n",
       "      <td>0.442549</td>\n",
       "      <td>0.363953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521610</td>\n",
       "      <td>0.506394</td>\n",
       "      <td>0.435055</td>\n",
       "      <td>0.525869</td>\n",
       "      <td>0.390700</td>\n",
       "      <td>0.524858</td>\n",
       "      <td>0.478981</td>\n",
       "      <td>0.509965</td>\n",
       "      <td>0.520434</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77996</th>\n",
       "      <td>0.522581</td>\n",
       "      <td>0.677694</td>\n",
       "      <td>0.397469</td>\n",
       "      <td>0.681666</td>\n",
       "      <td>0.327541</td>\n",
       "      <td>0.590112</td>\n",
       "      <td>0.389733</td>\n",
       "      <td>0.455139</td>\n",
       "      <td>0.467794</td>\n",
       "      <td>0.375672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504175</td>\n",
       "      <td>0.501952</td>\n",
       "      <td>0.435226</td>\n",
       "      <td>0.517287</td>\n",
       "      <td>0.387353</td>\n",
       "      <td>0.518052</td>\n",
       "      <td>0.469302</td>\n",
       "      <td>0.505998</td>\n",
       "      <td>0.502548</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77997</th>\n",
       "      <td>0.532845</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.400254</td>\n",
       "      <td>0.683759</td>\n",
       "      <td>0.322961</td>\n",
       "      <td>0.584981</td>\n",
       "      <td>0.387589</td>\n",
       "      <td>0.448374</td>\n",
       "      <td>0.470393</td>\n",
       "      <td>0.373412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500650</td>\n",
       "      <td>0.511076</td>\n",
       "      <td>0.435591</td>\n",
       "      <td>0.523066</td>\n",
       "      <td>0.379406</td>\n",
       "      <td>0.523126</td>\n",
       "      <td>0.453426</td>\n",
       "      <td>0.514232</td>\n",
       "      <td>0.487108</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77998</th>\n",
       "      <td>0.540281</td>\n",
       "      <td>0.675530</td>\n",
       "      <td>0.413560</td>\n",
       "      <td>0.681854</td>\n",
       "      <td>0.333672</td>\n",
       "      <td>0.586581</td>\n",
       "      <td>0.385783</td>\n",
       "      <td>0.445418</td>\n",
       "      <td>0.457761</td>\n",
       "      <td>0.350155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501399</td>\n",
       "      <td>0.510576</td>\n",
       "      <td>0.428731</td>\n",
       "      <td>0.529173</td>\n",
       "      <td>0.381493</td>\n",
       "      <td>0.530944</td>\n",
       "      <td>0.466449</td>\n",
       "      <td>0.521323</td>\n",
       "      <td>0.500644</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77999 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2      0.299407  0.679288  0.210996  0.613102  0.150618  0.522777  0.127314   \n",
       "3      0.284236  0.729573  0.173007  0.635995  0.111589  0.496627  0.109330   \n",
       "4      0.272220  0.750940  0.151656  0.647857  0.090840  0.491623  0.096680   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "77994  0.526264  0.677356  0.405371  0.684395  0.335519  0.593608  0.387241   \n",
       "77995  0.524471  0.684394  0.401440  0.688333  0.329967  0.594382  0.379672   \n",
       "77996  0.522581  0.677694  0.397469  0.681666  0.327541  0.590112  0.389733   \n",
       "77997  0.532845  0.682315  0.400254  0.683759  0.322961  0.584981  0.387589   \n",
       "77998  0.540281  0.675530  0.413560  0.681854  0.333672  0.586581  0.385783   \n",
       "\n",
       "              7         8         9  ...        33        34        35  \\\n",
       "0      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "2      0.438344  0.130090  0.381808  ...  0.574705  0.358198  0.506751   \n",
       "3      0.372887  0.124706  0.266505  ...  0.608846  0.450521  0.479627   \n",
       "4      0.370796  0.111904  0.266032  ...  0.641275  0.449075  0.491492   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "77994  0.459165  0.450325  0.363955  ...  0.523216  0.504606  0.434744   \n",
       "77995  0.458701  0.442549  0.363953  ...  0.521610  0.506394  0.435055   \n",
       "77996  0.455139  0.467794  0.375672  ...  0.504175  0.501952  0.435226   \n",
       "77997  0.448374  0.470393  0.373412  ...  0.500650  0.511076  0.435591   \n",
       "77998  0.445418  0.457761  0.350155  ...  0.501399  0.510576  0.428731   \n",
       "\n",
       "             36        37        38        39        40        41  Output  \n",
       "0      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000       A  \n",
       "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000       A  \n",
       "2      0.360233  0.452296  0.350743  0.506043  0.339431  0.557486       A  \n",
       "3      0.401771  0.453182  0.359019  0.534598  0.349776  0.602132       A  \n",
       "4      0.394166  0.473755  0.353244  0.558699  0.346559  0.625984       A  \n",
       "...         ...       ...       ...       ...       ...       ...     ...  \n",
       "77994  0.525846  0.400675  0.525645  0.488662  0.509252  0.529258       Z  \n",
       "77995  0.525869  0.390700  0.524858  0.478981  0.509965  0.520434       Z  \n",
       "77996  0.517287  0.387353  0.518052  0.469302  0.505998  0.502548       Z  \n",
       "77997  0.523066  0.379406  0.523126  0.453426  0.514232  0.487108       Z  \n",
       "77998  0.529173  0.381493  0.530944  0.466449  0.521323  0.500644       Z  \n",
       "\n",
       "[77999 rows x 43 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.rename(columns={42: 'Output'})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77999, 43)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values = 37963\n"
     ]
    }
   ],
   "source": [
    "# removing null values from our dataset\n",
    "\n",
    "null_values = dataset[dataset.iloc[:, 0] == 0]\n",
    "print(\"Number of null values =\", len(null_values.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping those null values from our dataset\n",
    "\n",
    "dataset.drop(null_values.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.299407</td>\n",
       "      <td>0.679288</td>\n",
       "      <td>0.210996</td>\n",
       "      <td>0.613102</td>\n",
       "      <td>0.150618</td>\n",
       "      <td>0.522777</td>\n",
       "      <td>0.127314</td>\n",
       "      <td>0.438344</td>\n",
       "      <td>0.130090</td>\n",
       "      <td>0.381808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574705</td>\n",
       "      <td>0.358198</td>\n",
       "      <td>0.506751</td>\n",
       "      <td>0.360233</td>\n",
       "      <td>0.452296</td>\n",
       "      <td>0.350743</td>\n",
       "      <td>0.506043</td>\n",
       "      <td>0.339431</td>\n",
       "      <td>0.557486</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.284236</td>\n",
       "      <td>0.729573</td>\n",
       "      <td>0.173007</td>\n",
       "      <td>0.635995</td>\n",
       "      <td>0.111589</td>\n",
       "      <td>0.496627</td>\n",
       "      <td>0.109330</td>\n",
       "      <td>0.372887</td>\n",
       "      <td>0.124706</td>\n",
       "      <td>0.266505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608846</td>\n",
       "      <td>0.450521</td>\n",
       "      <td>0.479627</td>\n",
       "      <td>0.401771</td>\n",
       "      <td>0.453182</td>\n",
       "      <td>0.359019</td>\n",
       "      <td>0.534598</td>\n",
       "      <td>0.349776</td>\n",
       "      <td>0.602132</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.272220</td>\n",
       "      <td>0.750940</td>\n",
       "      <td>0.151656</td>\n",
       "      <td>0.647857</td>\n",
       "      <td>0.090840</td>\n",
       "      <td>0.491623</td>\n",
       "      <td>0.096680</td>\n",
       "      <td>0.370796</td>\n",
       "      <td>0.111904</td>\n",
       "      <td>0.266032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.641275</td>\n",
       "      <td>0.449075</td>\n",
       "      <td>0.491492</td>\n",
       "      <td>0.394166</td>\n",
       "      <td>0.473755</td>\n",
       "      <td>0.353244</td>\n",
       "      <td>0.558699</td>\n",
       "      <td>0.346559</td>\n",
       "      <td>0.625984</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.260565</td>\n",
       "      <td>0.761086</td>\n",
       "      <td>0.142162</td>\n",
       "      <td>0.655401</td>\n",
       "      <td>0.082593</td>\n",
       "      <td>0.493751</td>\n",
       "      <td>0.091608</td>\n",
       "      <td>0.371733</td>\n",
       "      <td>0.114751</td>\n",
       "      <td>0.272436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659603</td>\n",
       "      <td>0.449525</td>\n",
       "      <td>0.506806</td>\n",
       "      <td>0.382283</td>\n",
       "      <td>0.482948</td>\n",
       "      <td>0.344662</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.340645</td>\n",
       "      <td>0.630759</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.265526</td>\n",
       "      <td>0.763699</td>\n",
       "      <td>0.146010</td>\n",
       "      <td>0.672900</td>\n",
       "      <td>0.075502</td>\n",
       "      <td>0.512883</td>\n",
       "      <td>0.077790</td>\n",
       "      <td>0.386985</td>\n",
       "      <td>0.105156</td>\n",
       "      <td>0.280604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674028</td>\n",
       "      <td>0.431689</td>\n",
       "      <td>0.497543</td>\n",
       "      <td>0.382958</td>\n",
       "      <td>0.486625</td>\n",
       "      <td>0.351145</td>\n",
       "      <td>0.573781</td>\n",
       "      <td>0.344029</td>\n",
       "      <td>0.640121</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77994</th>\n",
       "      <td>0.526264</td>\n",
       "      <td>0.677356</td>\n",
       "      <td>0.405371</td>\n",
       "      <td>0.684395</td>\n",
       "      <td>0.335519</td>\n",
       "      <td>0.593608</td>\n",
       "      <td>0.387241</td>\n",
       "      <td>0.459165</td>\n",
       "      <td>0.450325</td>\n",
       "      <td>0.363955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523216</td>\n",
       "      <td>0.504606</td>\n",
       "      <td>0.434744</td>\n",
       "      <td>0.525846</td>\n",
       "      <td>0.400675</td>\n",
       "      <td>0.525645</td>\n",
       "      <td>0.488662</td>\n",
       "      <td>0.509252</td>\n",
       "      <td>0.529258</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77995</th>\n",
       "      <td>0.524471</td>\n",
       "      <td>0.684394</td>\n",
       "      <td>0.401440</td>\n",
       "      <td>0.688333</td>\n",
       "      <td>0.329967</td>\n",
       "      <td>0.594382</td>\n",
       "      <td>0.379672</td>\n",
       "      <td>0.458701</td>\n",
       "      <td>0.442549</td>\n",
       "      <td>0.363953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521610</td>\n",
       "      <td>0.506394</td>\n",
       "      <td>0.435055</td>\n",
       "      <td>0.525869</td>\n",
       "      <td>0.390700</td>\n",
       "      <td>0.524858</td>\n",
       "      <td>0.478981</td>\n",
       "      <td>0.509965</td>\n",
       "      <td>0.520434</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77996</th>\n",
       "      <td>0.522581</td>\n",
       "      <td>0.677694</td>\n",
       "      <td>0.397469</td>\n",
       "      <td>0.681666</td>\n",
       "      <td>0.327541</td>\n",
       "      <td>0.590112</td>\n",
       "      <td>0.389733</td>\n",
       "      <td>0.455139</td>\n",
       "      <td>0.467794</td>\n",
       "      <td>0.375672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504175</td>\n",
       "      <td>0.501952</td>\n",
       "      <td>0.435226</td>\n",
       "      <td>0.517287</td>\n",
       "      <td>0.387353</td>\n",
       "      <td>0.518052</td>\n",
       "      <td>0.469302</td>\n",
       "      <td>0.505998</td>\n",
       "      <td>0.502548</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77997</th>\n",
       "      <td>0.532845</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.400254</td>\n",
       "      <td>0.683759</td>\n",
       "      <td>0.322961</td>\n",
       "      <td>0.584981</td>\n",
       "      <td>0.387589</td>\n",
       "      <td>0.448374</td>\n",
       "      <td>0.470393</td>\n",
       "      <td>0.373412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500650</td>\n",
       "      <td>0.511076</td>\n",
       "      <td>0.435591</td>\n",
       "      <td>0.523066</td>\n",
       "      <td>0.379406</td>\n",
       "      <td>0.523126</td>\n",
       "      <td>0.453426</td>\n",
       "      <td>0.514232</td>\n",
       "      <td>0.487108</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77998</th>\n",
       "      <td>0.540281</td>\n",
       "      <td>0.675530</td>\n",
       "      <td>0.413560</td>\n",
       "      <td>0.681854</td>\n",
       "      <td>0.333672</td>\n",
       "      <td>0.586581</td>\n",
       "      <td>0.385783</td>\n",
       "      <td>0.445418</td>\n",
       "      <td>0.457761</td>\n",
       "      <td>0.350155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501399</td>\n",
       "      <td>0.510576</td>\n",
       "      <td>0.428731</td>\n",
       "      <td>0.529173</td>\n",
       "      <td>0.381493</td>\n",
       "      <td>0.530944</td>\n",
       "      <td>0.466449</td>\n",
       "      <td>0.521323</td>\n",
       "      <td>0.500644</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40036 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "2      0.299407  0.679288  0.210996  0.613102  0.150618  0.522777  0.127314   \n",
       "3      0.284236  0.729573  0.173007  0.635995  0.111589  0.496627  0.109330   \n",
       "4      0.272220  0.750940  0.151656  0.647857  0.090840  0.491623  0.096680   \n",
       "5      0.260565  0.761086  0.142162  0.655401  0.082593  0.493751  0.091608   \n",
       "6      0.265526  0.763699  0.146010  0.672900  0.075502  0.512883  0.077790   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "77994  0.526264  0.677356  0.405371  0.684395  0.335519  0.593608  0.387241   \n",
       "77995  0.524471  0.684394  0.401440  0.688333  0.329967  0.594382  0.379672   \n",
       "77996  0.522581  0.677694  0.397469  0.681666  0.327541  0.590112  0.389733   \n",
       "77997  0.532845  0.682315  0.400254  0.683759  0.322961  0.584981  0.387589   \n",
       "77998  0.540281  0.675530  0.413560  0.681854  0.333672  0.586581  0.385783   \n",
       "\n",
       "              7         8         9  ...        33        34        35  \\\n",
       "2      0.438344  0.130090  0.381808  ...  0.574705  0.358198  0.506751   \n",
       "3      0.372887  0.124706  0.266505  ...  0.608846  0.450521  0.479627   \n",
       "4      0.370796  0.111904  0.266032  ...  0.641275  0.449075  0.491492   \n",
       "5      0.371733  0.114751  0.272436  ...  0.659603  0.449525  0.506806   \n",
       "6      0.386985  0.105156  0.280604  ...  0.674028  0.431689  0.497543   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "77994  0.459165  0.450325  0.363955  ...  0.523216  0.504606  0.434744   \n",
       "77995  0.458701  0.442549  0.363953  ...  0.521610  0.506394  0.435055   \n",
       "77996  0.455139  0.467794  0.375672  ...  0.504175  0.501952  0.435226   \n",
       "77997  0.448374  0.470393  0.373412  ...  0.500650  0.511076  0.435591   \n",
       "77998  0.445418  0.457761  0.350155  ...  0.501399  0.510576  0.428731   \n",
       "\n",
       "             36        37        38        39        40        41  Output  \n",
       "2      0.360233  0.452296  0.350743  0.506043  0.339431  0.557486       A  \n",
       "3      0.401771  0.453182  0.359019  0.534598  0.349776  0.602132       A  \n",
       "4      0.394166  0.473755  0.353244  0.558699  0.346559  0.625984       A  \n",
       "5      0.382283  0.482948  0.344662  0.565404  0.340645  0.630759       A  \n",
       "6      0.382958  0.486625  0.351145  0.573781  0.344029  0.640121       A  \n",
       "...         ...       ...       ...       ...       ...       ...     ...  \n",
       "77994  0.525846  0.400675  0.525645  0.488662  0.509252  0.529258       Z  \n",
       "77995  0.525869  0.390700  0.524858  0.478981  0.509965  0.520434       Z  \n",
       "77996  0.517287  0.387353  0.518052  0.469302  0.505998  0.502548       Z  \n",
       "77997  0.523066  0.379406  0.523126  0.453426  0.514232  0.487108       Z  \n",
       "77998  0.529173  0.381493  0.530944  0.466449  0.521323  0.500644       Z  \n",
       "\n",
       "[40036 rows x 43 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40036, 43)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40036, 42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dataset.iloc[:, :-1]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40036,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset.iloc[:, -1]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% Train, 20% test \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3, weights=\"distance\", algorithm=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3, weights='distance')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "knn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predKNN=knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.41408591408592 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "knnAc= metrics.accuracy_score(y_test, y_predKNN)*100\n",
    "print(\"Accuracy:\",knnAc,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 100.0 % \n",
      "\n",
      "Testing Accuracy: 98.41408591408592 %\n"
     ]
    }
   ],
   "source": [
    "#Check for overfitting and underfitting\n",
    "print(\"Training Accuracy:\",knn.score(x_train, y_train)*100,\"%\",\"\\n\")\n",
    "print(\"Testing Accuracy:\",knn.score(x_test, y_test)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Decision Tree\n",
    "from sklearn import tree\n",
    "#Create a Decision Tree Classifier\n",
    "dt = tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth=26, min_samples_split=2, min_samples_leaf=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=26, min_samples_leaf=7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=26, min_samples_leaf=7)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=26, min_samples_leaf=7)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predDT=dt.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.17232767232767 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "DTac = metrics.accuracy_score(y_test, y_predDT)*100\n",
    "print(\"Accuracy:\",DTac,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 94.32683901586113 % \n",
      "\n",
      "Testing Accuracy: 90.03496503496503 %\n"
     ]
    }
   ],
   "source": [
    "#Check for overfitting and underfitting\n",
    "print(\"Training Accuracy:\",dt.score(x_train, y_train)*100,\"%\",\"\\n\")\n",
    "print(\"Testing Accuracy:\",dt.score(x_test, y_test)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF=RandomForestClassifier(criterion=\"entropy\",n_estimators=100, max_depth=26 , min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=26)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=26)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=26)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predRF=RF.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.65134865134864 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "RFac = metrics.accuracy_score(y_test, y_predRF)*100\n",
    "print(\"Accuracy:\",RFac,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 100.0 % \n",
      "\n",
      "Testing Accuracy: 98.65134865134864 %\n"
     ]
    }
   ],
   "source": [
    "#Check for overfitting and underfitting\n",
    "print(\"Training Accuracy:\",RF.score(x_train, y_train)*100,\"%\",\"\\n\")\n",
    "print(\"Testing Accuracy:\",RF.score(x_test, y_test)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xAxis = ['KNN','DT', 'RF']\n",
    "yAxis = [knnAc, DTac, RFac]\n",
    "\n",
    "dframe = pd.DataFrame({\"Classifiers\" : xAxis, \"Accuracy\" : yAxis})\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "splot = sns.barplot(x = \"Classifiers\",y = \"Accuracy\", data = dframe)\n",
    "plt.xlabel(\"Classifiers\", size=16)\n",
    "plt.ylabel(\"Accuracy\", size=16)\n",
    "plt.savefig(\"BSL Sign Digits - Accuracy Comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>98.414086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>90.172328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>98.651349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model   Accuracy\n",
       "0            KNN  98.414086\n",
       "1  Decision tree  90.172328\n",
       "2  Random Forest  98.651349"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare = pd.DataFrame({'Model': ['KNN','Decision tree','Random Forest'], \n",
    "                        'Accuracy': [KNNac,DTac,RFac]})\n",
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[254,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0],\n",
       "       [  0, 280,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0, 389,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0, 362,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0, 336,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   1],\n",
       "       [  0,   1,   0,   1,   0, 368,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 312,   1,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   1, 336,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 341,   1,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   1,   0,   0,   0,   0,   3, 324,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 357,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   1,   3,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0, 456,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   1,   2,   0,   3,   0,   0,   0,   0,   0,   0,   0, 128,\n",
       "          6,   0,   0,   1,   0,   1,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   1,   1,   0,   0,   0,   0,   0,   0,   4,\n",
       "        153,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1],\n",
       "       [  0,   0,   0,   1,   0,   1,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0, 296,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   1],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0, 210,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          1,   0,   2, 146,   0,   0,   0,   0,   1,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,\n",
       "          0,   0,   0,   0, 305,   0,   0,   7,   0,   0,   1,   0,   0],\n",
       "       [  1,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "          0,   1,   1,   0,   1, 316,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  1,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 360,   0,   0,   1,   3,   1,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   7,   0,   0, 299,   7,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   3,   0,   0,\n",
       "          0,   0,   0,   0,   1,   0,   0,   2, 310,   0,   1,   0,   0],\n",
       "       [  0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0, 324,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,\n",
       "          0,   0,   1,   0,   0,   0,   0,   0,   0,   0, 244,   0,   0],\n",
       "       [  1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 308,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 386]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cmatrix = confusion_matrix(y_test, y_predRF)\n",
    "Cmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(Cmatrix, center = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      0.98      0.99       257\n",
      "           B       0.99      1.00      0.99       280\n",
      "           C       0.99      1.00      1.00       389\n",
      "           D       0.99      1.00      1.00       363\n",
      "           E       0.98      0.99      0.99       338\n",
      "           F       0.99      0.99      0.99       371\n",
      "           G       1.00      1.00      1.00       313\n",
      "           H       0.99      1.00      1.00       337\n",
      "           I       0.98      0.99      0.99       344\n",
      "           J       1.00      0.98      0.99       328\n",
      "           K       0.99      0.99      0.99       361\n",
      "           L       1.00      1.00      1.00       457\n",
      "           M       0.97      0.89      0.93       142\n",
      "           N       0.97      0.96      0.96       161\n",
      "           O       0.99      0.98      0.99       301\n",
      "           P       0.98      0.99      0.98       214\n",
      "           Q       0.97      0.96      0.96       151\n",
      "           R       0.96      0.95      0.96       314\n",
      "           S       0.98      0.98      0.98       322\n",
      "           T       0.99      0.98      0.99       367\n",
      "           U       0.95      0.95      0.95       314\n",
      "           V       0.97      0.97      0.97       318\n",
      "           W       1.00      0.99      1.00       325\n",
      "           X       0.97      0.98      0.98       246\n",
      "           Y       0.99      1.00      0.99       309\n",
      "           Z       1.00      1.00      1.00       386\n",
      "\n",
      "    accuracy                           0.99      8008\n",
      "   macro avg       0.98      0.98      0.98      8008\n",
      "weighted avg       0.99      0.99      0.99      8008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predRF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26226</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34842</th>\n",
       "      <td>L</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9724</th>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10430</th>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10698</th>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15672</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50973</th>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42517</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68359</th>\n",
       "      <td>W</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77936</th>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8008 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      original predicted\n",
       "26226        I         I\n",
       "34842        L         L\n",
       "9724         D         D\n",
       "10430        D         D\n",
       "10698        D         D\n",
       "...        ...       ...\n",
       "15672        F         F\n",
       "50973        Q         Q\n",
       "42517        O         O\n",
       "68359        W         W\n",
       "77936        Z         Z\n",
       "\n",
       "[8008 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'original' : y_test,'predicted' : y_predRF})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RF_Model.pkl']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save the model in a file\n",
    "joblib.dump(RF, 'RF_Model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
